# FWDNXT SDK

FWDNXT Software Developement Kit - SDK
To register and download, please send a request to info@fwdnxt.com

# FWDNXT set-up steps

1. Obtain necessary hardware: This SDK supposes that you are working on a desktop computer with Micron FPGA boards on a PCI backplane (AC-510 and EX-750 for example).
2. Install pico-computing tools and FWDNXT SDK. Check [this](docs/Installation.md) for more details
3. Run a sample example. Check these docs [3](docs/GettingStarted_in_python.md) and [4](docs/GettingStarted_in_C.md) for more
4. Create your own application. Check these docs [5](docs/TutorialMultiFPGACluster.md), [8](docs/Supported_layers.md) and [9](docs/Tensorflow.md)

## FWDNXT SDK Documentation:

[**1. Installation**](docs/Installation.md): install SDK

[**2. Tutorial - Deep Learning**](docs/GettingStarted_DeepLearning.md): general information about deep learning.

[**3. Tutorial - Inference on the Inference Engine**](docs/GettingStarted_in_python.md): getting started tutorial for running inference on the Inference Engine.

[**4. Tutorial - Inference on the Inference Engine using C**](docs/GettingStarted_in_C.md): getting started tutorial for running inference on the Inference Engine using C.

[**5. Tutorial - Multi FPGA and Cluster**](docs/TutorialMultiFPGACluster.md): tutorial for running inference on multiple FPGAs and clusters.

[**6. Python API**](docs/PythonAPI.md): Documentation of the python API.

[**7. C API**](docs/C%20API.md): Documentation of the C/C++ API.

[**8. Supported Models**](docs/Supported_layers.md): List of supported layers and models tested on the Inference Engine.

[**9. Using with Tensorflow**](docs/Tensorflow.md): Tutorial on using tensorflow with the Inference Engine.

[**10. Troubleshooting**](docs/Troubleshooting.md): Troubleshooting common issues and answering common questions.



Please report issues and bugs [here](https://github.com/FWDNXT/SDK/issues).


